# -*- coding: utf-8 -*-
"""СпецГлМат_ДЗ1_МышеловаПолинаСергеевна.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iHo15EeI3GcPHSloDTh47Z8Pg4jiourH
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import scipy
from scipy.spatial.distance import pdist, squareform
import random
import operator
import math

data = pd.read_csv('/content/drive/MyDrive/Hotel Reservations.csv')

data.head()

# количество строк и столбцов
data.shape

# реализуем алгоритм резервуарного сэмплинга
import random
def generator(max):
    number = 1
    while number < max:
        number += 1
        yield number
# Создаём генератор потока
stream = generator(36275)
# оставим 5000 строк
k=5000
reservoir = []
for i, element in enumerate(stream):
    if i+1<= k:
        reservoir.append(element)
    else:
        probability = k/(i+1)
        if random.random() < probability:
            # Сохраняем элемент из потока, удаляя ранее добавленный 
             reservoir[random.choice(range(0,k))] = element

reservoir = np.array(reservoir)
data = pd.DataFrame(data, index=reservoir)

data.head()

data['arrival_date'].unique()

data.info()

# удаление пустых значений
data = data.dropna()

data['type_of_meal_plan'].unique()

data['type_of_meal_plan'] = data['type_of_meal_plan'].map({'Meal Plan 1': 0,
                                                           'Not Selected': 3,
                                                           'Meal Plan 2': 1,
                                                           'Meal Plan 3': 2})

data['room_type_reserved'].unique()

data['room_type_reserved'] = data['room_type_reserved'].map({'Room_Type 1': 0,
                                                           'Room_Type 2': 1,
                                                           'Room_Type 3': 2,
                                                           'Room_Type 4': 3,
                                                           'Room_Type 5': 4,
                                                           'Room_Type 6': 5,
                                                           'Room_Type 7': 6})

data['market_segment_type'].unique()

data['market_segment_type'] = data['market_segment_type'].map({'Offline': 0,
                                                           'Online': 1,
                                                           'Corporate': 2,
                                                           'Aviation': 3,
                                                           'Complementary': 4})

''' исключим первую и последную колонку Booking_ID и booking_status типа object,
которые точно не будут использованы в анализе'''
data.drop(axis=1, columns=['Booking_ID', 'booking_status'], inplace=True)

data.head()

fig, ax = plt.subplots(figsize=(17,17))
sns.heatmap(data.corr(), annot=True, ax=ax, cmap='coolwarm')
plt.show()

data = data[['no_of_adults', 'no_of_children', 'type_of_meal_plan',
             'required_car_parking_space', 'arrival_month',
             'market_segment_type']]
data.to_csv('/content/drive/MyDrive/Hotel Reservations_2.csv', index=False)

data

fig, ax = plt.subplots(figsize=(10,7))
sns.heatmap(data.corr(), annot=True, ax=ax, cmap='coolwarm')
plt.show()

sns.countplot(data, x='no_of_adults')

sns.countplot(data, x='no_of_children')

sns.countplot(data, x='market_segment_type')

sns.countplot(data, x='type_of_meal_plan')

sns.countplot(data, x='required_car_parking_space')

sns.countplot(data, x='arrival_month')

sns.pairplot(data)

#нормализуем данные
scaler = preprocessing.MinMaxScaler()
data_norm = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)

data_norm.head()

matrix = pd.DataFrame(squareform(pdist(data_norm, metric='euclidean')))
matrix

WCSS = []

for n_cluster in range(2, 15):
    kmeans = KMeans(n_clusters=n_cluster, init='k-means++', max_iter=300, n_init=10)
    kmeans.fit(data_norm)
    WCSS.append(kmeans.inertia_)

plt.plot(range(2, 15), WCSS)
plt.title('The elbow method')
plt.xlabel('Количество кластеров')
plt.ylabel('WCSS')
plt.show()

n = len(data_norm)
k = 4 # количество кластеров
m = 1.7 # фаззификатор

def initializeMembershipMatrix(): # рассчитаем матрицу принадлежности элементов к кластерам
    membership_mat = []
    for i in range(n):
        random_num_list = [random.random() for i in range(k)]
        summation = sum(random_num_list)
        temp_list = [x/summation for x in random_num_list]
        
        flag = temp_list.index(max(temp_list))
        for j in range(0,len(temp_list)):
            if(j == flag):
                temp_list[j] = 1
            else:
                temp_list[j] = 0
        
        membership_mat.append(temp_list)
    return membership_mat

membership_mat = initializeMembershipMatrix()

def calculateClusterCenter(membership_mat): # рассчитаем центры кластеров
    cluster_mem_val = list(zip(*membership_mat))
    cluster_centers = []
    for j in range(k):
        x = list(cluster_mem_val[j])
        xraised = [p ** m for p in x]
        denominator = sum(xraised)
        temp_num = []
        for i in range(n):
            data_point = list(data_norm.iloc[i])
            prod = [xraised[i] * val for val in data_point]
            temp_num.append(prod)
        numerator = map(sum, list(zip(*temp_num)))
        center = [z/denominator for z in numerator]
        cluster_centers.append(center)
    return cluster_centers

calculateClusterCenter(membership_mat)

def updateMembershipValue(membership_mat, cluster_centers): # обновим матрицу принадлежности
    p = float(2/(m-1))
    for i in range(n):
        x = list(data_norm.iloc[i])
        distances = [np.linalg.norm(np.array(list(map(operator.sub, x, cluster_centers[j])))) for j in range(k)]
        for j in range(k):
            den = sum([math.pow(float(distances[j]/distances[c]), p) for c in range(k)])
            membership_mat[i][j] = float(1/den)       
    return membership_mat

def getClusters(membership_mat): # вывести лэйблы кластеров
    cluster_labels = list()
    for i in range(n):
        max_val, idx = max((val, idx) for (idx, val) in enumerate(membership_mat[i]))
        cluster_labels.append(idx)
    return cluster_labels

def fuzzyCMeansClustering():
    '''Реализуем Метод нечёткой кластеризации C-средних
    с центрами кластеров в случайных местах в многомерном гауссовском распределении с нулевым средним и единичной дисперсией
    '''
    membership_mat = initializeMembershipMatrix()
    curr = 0
    acc=[]
    mean = [0, 0]
    cov = [[1, 0], [0, 1]]
    
    lis1,cent_temp=[],[]
    
    for i in range(0,k):
        Z = list(np.random.multivariate_normal(mean, cov))
        Z1 = list(np.random.multivariate_normal(mean, cov))
        lis1 = Z+Z1
        cent_temp.append(lis1)
       
    while curr < 100:
        if(curr == 0):
            cluster_centers = cent_temp
            print("Cluster Centers:")
            print(np.array(cluster_centers))
        else:
            cluster_centers = calculateClusterCenter(membership_mat)
        #cluster_centers = calculateClusterCenter(membership_mat)
        membership_mat = updateMembershipValue(membership_mat, cluster_centers)
        cluster_labels = getClusters(membership_mat)
        acc.append(cluster_labels)
        curr += 1
    print("---------------------------")
    print("Membership Matrix:")
    print(np.array(membership_mat))
    return cluster_labels, cluster_centers, acc

labels, centers, acc = fuzzyCMeansClustering()

data_norm['labels'] = labels

data_norm['labels'].unique()

data_norm.head()

from sklearn import metrics
from sklearn.metrics import pairwise_distances, silhouette_score

silhouette_score(data_norm, labels, metric='euclidean')

sns.scatterplot(data_norm, x='no_of_adults', y='labels')

sns.scatterplot(data_norm, x='market_segment_type', y='labels')

sns.scatterplot(data_norm, x='market_segment_type', y='no_of_adults', hue='labels')

sns.scatterplot(data_norm, x='no_of_adults', y='no_of_children', hue='labels')

data['labels'] = labels
data.head()

label_0 = data[data['labels'] == 0]
label_0['no_of_adults'].value_counts()

label_0 = data[data['labels'] == 1]
label_0['no_of_adults'].value_counts()

label_2 = data[data['labels'] == 2]
label_2['no_of_adults'].value_counts()

label_3 = data[data['labels'] == 3]
label_3['no_of_adults'].value_counts()